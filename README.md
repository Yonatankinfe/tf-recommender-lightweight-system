# tf-recommender-lightweight-system
A lightweight content-based recommendation system built with Python and TensorFlow/Keras, exposed via a simple REST API with automatic API key generation.
# Content-Based Recommendation System

This project implements a lightweight, simple content-based recommendation system using Python. It leverages TF-IDF for feature extraction, TensorFlow/Keras for generating neural network embeddings, and FastAPI for serving a RESTful API.

## ğŸŒŸ Features

*   **Content-Based Recommendations**: Recommends items similar to a given item based on their content (e.g., title, description, tags).
*   **Neural Network Embeddings**: Uses a simple Multi-Layer Perceptron (MLP), trained in an autoencoder-like fashion on TF-IDF features, to generate item embeddings.
*   **TF-IDF**: Utilizes Term Frequency-Inverse Document Frequency for initial text feature extraction.
*   **RESTful API**: Exposes recommendation functionality via a FastAPI application.
*   **API Key Authentication**: Secures the recommendation endpoint using API keys.
*   **Automatic Key Generation**: Includes an endpoint to generate new API keys, which are stored in a `.env` file.

## ğŸ“‚ Project Structure
recommendation_system/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ items.csv # Example item data (e.g., item_id, title, description)
â”œâ”€â”€ models/ # Saved models and artifacts (created by train.py)
â”‚ â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚ â”œâ”€â”€ embedding_model.keras
â”‚ â””â”€â”€ item_embeddings.pkl
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ auth.py # API key handling and authentication
â”‚ â”œâ”€â”€ data_loader.py # Loads and prepares data
â”‚ â”œâ”€â”€ main.py # FastAPI application entrypoint
â”‚ â”œâ”€â”€ model.py # Keras model definition
â”‚ â”œâ”€â”€ preprocessing.py # Text preprocessing and TF-IDF logic
â”‚ â”œâ”€â”€ recommender.py # Recommendation logic (cosine similarity)
â”‚ â”œâ”€â”€ train.py # Script to train the model and generate artifacts
â”‚ â””â”€â”€ utils.py # Utility functions (saving/loading artifacts)
â”œâ”€â”€ venv/ # Python virtual environment (recommended)
â”œâ”€â”€ .env # Stores API keys (created automatically or manually)
â”œâ”€â”€ README.md # This file
â””â”€â”€ requirements.txt # Python dependencies

*   `data/`: Contains the raw data for items.
*   `models/`: Stores the pre-trained TF-IDF vectorizer, the Keras embedding model, and the generated item embeddings.
*   `src/`: Contains all the Python source code for the application.

## ğŸš€ Setup

1.  **Clone the Repository (or place project files):**
    ```bash
    # If you have the project folder named 'recommendation_system'
    cd recommendation_system
    ```

2.  **Create and Activate a Virtual Environment:**
    (Recommended to keep dependencies isolated)
    ```bash
    python3 -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install Dependencies:**
    Ensure you have a `requirements.txt` file with all necessary packages.
    ```bash
    pip install -r requirements.txt
    ```
    *(If `requirements.txt` is not provided, you'll need to create it, e.g., `pip freeze > requirements.txt` after installing packages like `tensorflow`, `scikit-learn`, `fastapi`, `uvicorn`, `python-dotenv`, `pandas`)*

## ğŸ‹ï¸ Training the Model

Run the training script from the project's root directory to process the data, train the embedding model, and generate the necessary artifacts in the `models/` directory.

```bash
python src/train.py
